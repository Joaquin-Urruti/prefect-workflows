# Tutorial: Using Prefect with Docker

## Table of Contents

1. [Introduction](#introduction)
2. [Project Structure](#project-structure)
3. [Docker Components](#docker-components)
4. [Initial Setup](#initial-setup)
5. [Service Deployment](#service-deployment)
6. [Create and Run Flows](#create-and-run-flows)
7. [Schedule Flows with Deployments](#schedule-flows-with-deployments)
8. [Example: Daily Backup at 3:00 AM](#example-daily-backup-at-300-am)
9. [Useful Commands](#useful-commands)
10. [Monitoring and Logs](#monitoring-and-logs)

---

## Introduction

**Prefect** is a modern workflow orchestration platform that allows you to:
- Schedule and execute automated tasks
- Monitor execution in real-time
- Manage task dependencies
- Handle errors and automatic retries

This project uses **Docker** to run Prefect, which facilitates deployment and management of all necessary services.

---

## Project Structure

```
prefect-workflows/
├── docker-compose.yml      # Docker container orchestration
├── Dockerfile             # Custom image for worker
├── pyproject.toml         # Project dependencies (uv)
├── uv.lock               # Dependency lockfile
├── scripts/              # Your Prefect flows
│   ├── backup_lotes.py   # Daily backup at 3 AM
│   ├── generar_kmz.py    # Weekly KMZ generation
│   ├── test.py           # Test flow (every minute)
│   └── Modules/          # Shared modules
├── outputs/              # Files generated by flows
├── logs/                 # Service logs
│   ├── server/
│   ├── services/
│   └── worker/
└── data/                 # Persistent data
    ├── postgres/
    └── redis/
```

---

## Docker Components

### Services in docker-compose.yml

1. **postgres**: Database to store Prefect state
2. **redis**: Messaging system for service communication
3. **prefect-server**: API and web server (UI at http://localhost:4200)
4. **prefect-services**: Internal Prefect services (scheduler, etc.)
5. **prefect-worker**: Flow executor (process worker)

### Shared Volumes

- `./scripts:/app/scripts` - Your Python flows
- `./outputs:/app/outputs` - Execution results
- `./logs:/root/.prefect/logs` - Prefect logs
- `./data/postgres` and `./data/redis` - Data persistence

---

## Initial Setup

### 1. Prerequisites

- Docker and Docker Compose installed
- Python 3.13 (optional, for local development)
- uv (package manager, installed in container)

### 2. Environment Variables (Optional)

Create a `.env` file in the project root:

```env
PREFECT_POSTGRES_USER=prefect
PREFECT_POSTGRES_PASSWORD=prefect
PREFECT_POSTGRES_DB=prefect
TZ=America/Argentina/Buenos_Aires
```

### 3. Install Local Dependencies (Optional)

If you want to develop locally:

```bash
# Install uv
pip install uv

# Sync dependencies
uv sync
```

---

## Service Deployment

### Start all services

```bash
# Build and start all containers
docker compose up -d --build

# Check service status
docker compose ps

# View logs in real-time
docker compose logs -f
```

### Verify everything works

1. **Web Interface**: Open http://localhost:4200
2. **Check service health**:
   ```bash
   docker compose ps
   # All should be "healthy" or "running"
   ```

### Stop services

```bash
# Stop without removing data
docker compose down

# Stop and remove volumes (caution! deletes data)
docker compose down -v
```

---

## Create and Run Flows

### Anatomy of a Prefect Flow

A typical Prefect flow has this structure:

```python
from prefect import task, flow
from prefect import get_run_logger

@task(name="My task")
def my_task(parameter: str):
    """An individual task"""
    logger = get_run_logger()
    logger.info(f"Executing task with: {parameter}")
    # Your logic here
    return result

@flow(name="My Main Flow")
def my_flow(arg1: str = "value"):
    """The main flow that orchestrates tasks"""
    logger = get_run_logger()
    logger.info("Starting flow")

    # Execute tasks
    result = my_task(arg1)

    return result

if __name__ == "__main__":
    # Deploy with schedule
    my_flow.from_source(
        source="/app/scripts",
        entrypoint="my_script.py:my_flow",
    ).deploy(
        name="my-flow-daily",
        work_pool_name="local-pool",
        cron="0 9 * * *",  # Daily at 9 AM
        parameters={"arg1": "value"},
        tags=["example"],
    )
```

### Execute a Flow

**Deploy the flow** (creates scheduled deployment):
```bash
docker compose exec prefect-worker python scripts/my_script.py
```

**Run manually from CLI**:
```bash
docker compose exec prefect-server prefect deployment run "My Main Flow/my-flow-daily"
```

**Run from UI**:
1. Go to http://localhost:4200
2. Navigate to Deployments
3. Click "Run" → "Quick run"

---

## Schedule Flows with Deployments

### Create a Work Pool (First Time Only)

```bash
# Enter server container
docker compose exec prefect-server bash

# Create work pool
prefect work-pool create local-pool --type process

# Verify
prefect work-pool ls
exit
```

### Deploy a Flow with Schedule

Simply run the script that contains `.deploy()` at the end:

```bash
docker compose exec prefect-worker python scripts/backup_lotes.py
```

This will:
1. Register the flow with Prefect
2. Create a deployment with the specified schedule
3. Start executing automatically according to the cron schedule

### Verify Worker is Active

```bash
# View worker logs
docker compose logs -f prefect-worker

# You should see:
# "Worker started! Polling pool 'local-pool'"
```

---

## Example: Daily Backup at 3:00 AM

Let's look at how `backup_lotes.py` is configured to run daily at 3:00 AM.

### The Flow Structure

```python
# scripts/backup_lotes.py
from prefect import task, flow
from prefect import get_run_logger

@task(name="Fetch data")
def fetch_data(campania: str):
    logger = get_run_logger()
    logger.info(f'Fetching data for campaign {campania}')
    # ... your data fetching logic ...
    return data

@flow(name="Backup Databaler Lotes")
def backup_databaler_flow(campania: str = "25/26", test: bool = False):
    """
    Main flow for backing up Databaler data

    Args:
        campania: Campaign year in format "YY/YY"
        test: If True, save to ./outputs. If False, use production directories.
    """
    logger = get_run_logger()
    logger.info(f"Starting backup for campaign {campania} (test mode: {test})")

    # Execute tasks
    data = fetch_data(campania)
    # ... more tasks ...

    logger.info("Backup completed successfully!")
    return results

if __name__ == "__main__":
    # Deploy with schedule
    backup_databaler_flow.from_source(
        source="/app/scripts",
        entrypoint="backup_lotes.py:backup_databaler_flow",
    ).deploy(
        name="backup-lotes-daily-3am",
        work_pool_name="local-pool",
        cron="0 3 * * *",  # Daily at 3:00 AM
        parameters={
            "campania": "25/26",
            "test": False  # Production mode
        },
        tags=["backup", "databaler", "daily", "production"],
        description="Daily backup of Databaler data at 3:00 AM",
    )
```

### Deploy the Backup Flow

```bash
docker compose exec prefect-worker python scripts/backup_lotes.py
```

### Verify in UI

1. Open http://localhost:4200
2. Go to **Deployments**
3. You should see `Backup Databaler Lotes/backup-lotes-daily-3am`
4. Check the next scheduled run

### Test Manual Execution

```bash
# From CLI
docker compose exec prefect-server bash
prefect deployment run 'Backup Databaler Lotes/backup-lotes-daily-3am'

# From UI: Click "Run" → "Quick run"
```

### Cron Schedule Explanation

The cron format `"0 3 * * *"` means:

```
┌───────────── minute (0-59)
│ ┌───────────── hour (0-23)
│ │ ┌───────────── day of month (1-31)
│ │ │ ┌───────────── month (1-12)
│ │ │ │ ┌───────────── day of week (0-6, Sunday=0)
│ │ │ │ │
0 3 * * *
```

**Common schedule examples:**

```python
# Every hour
cron="0 * * * *"

# Daily at midnight
cron="0 0 * * *"

# Every Monday at 9:00 AM
cron="0 9 * * 1"

# Every 15 minutes
cron="*/15 * * * *"

# Weekdays at 6 AM
cron="0 6 * * 1-5"
```

Use https://crontab.guru/ to generate cron expressions.

---

## Useful Commands

### Docker Compose

```bash
# View logs of specific service
docker compose logs -f prefect-worker
docker compose logs -f prefect-server

# Restart a service
docker compose restart prefect-worker

# Rebuild worker image after changes
docker compose up -d --build prefect-worker

# View resource usage
docker stats
```

### Prefect CLI (inside container)

```bash
# Enter server container
docker compose exec prefect-server bash

# View work pools
prefect work-pool ls

# View deployments
prefect deployment ls

# View recent runs
prefect flow-run ls --limit 10

# Pause/resume a deployment
prefect deployment pause 'Backup Databaler Lotes/backup-lotes-daily-3am'
prefect deployment resume 'Backup Databaler Lotes/backup-lotes-daily-3am'

# Delete a deployment
prefect deployment delete 'Backup Databaler Lotes/backup-lotes-daily-3am'
```

### Execute Python Scripts

```bash
# Deploy a flow (creates scheduled deployment)
docker compose exec prefect-worker python scripts/my_flow.py

# Run flow directly (no scheduling)
docker compose exec prefect-worker python -c "from scripts.my_flow import my_flow; my_flow()"
```

---

## Monitoring and Logs

### 1. Web Interface (UI)

**URL**: http://localhost:4200

Features:
- View all flows and deployments
- Monitor executions in real-time
- View logs for each task
- Dependency graph (DAG)
- Statistics and metrics

### 2. System Logs

Logs are saved in `./logs/`:

```bash
# View worker logs
tail -f logs/worker/prefect.log

# View server logs
tail -f logs/server/prefect.log

# Search for errors
grep -r "ERROR" logs/
```

### 3. Docker Logs

```bash
# Logs from all services
docker compose logs -f

# Logs from specific service
docker compose logs -f prefect-worker

# Last 100 lines
docker compose logs --tail=100 prefect-worker
```

### 4. Check Execution Status

From Prefect CLI:

```bash
docker compose exec prefect-server bash

# View recent runs
prefect flow-run ls --limit 20

# View details of specific run
prefect flow-run inspect <flow-run-id>

# View only failed runs
prefect flow-run ls --state-type FAILED
```

---

## Common Troubleshooting

### Worker not executing flows

**Verify worker is running:**
```bash
docker compose logs prefect-worker
```

Should show: `Worker started! Polling pool 'local-pool'`

**Verify work pool exists:**
```bash
docker compose exec prefect-server prefect work-pool ls
```

### Schedules not executing

**Verify prefect-services is running:**
```bash
docker compose ps prefect-services
```

This service includes the scheduler. If not running, scheduled deployments won't execute.

### Module import errors

If scripts can't import `Modules`:

1. Verify `./scripts/Modules` exists in container
2. Ensure volume is mounted correctly: `docker compose exec prefect-worker ls -la scripts/Modules`
3. Restart worker: `docker compose restart prefect-worker`

### Corrupted database

If Postgres has issues:

```bash
# Stop everything
docker compose down

# Remove postgres data (you'll lose data!)
rm -rf data/postgres/*

# Start again
docker compose up -d
```

---

## Best Practices

1. **Use test mode first**
   ```python
   my_flow(test=True)  # Saves to ./outputs
   ```

2. **Add descriptive tags to deployments**
   ```python
   tags=["backup", "daily", "production"]
   ```

3. **Configure retries for critical tasks**
   ```python
   @task(name="Fetch data", retries=3, retry_delay_seconds=60)
   def fetch_data():
       # ...
   ```

4. **Use logging appropriately**
   ```python
   logger = get_run_logger()
   logger.info("General information")
   logger.warning("Warning")
   logger.error("Error")
   ```

5. **Monitor resources**
   ```bash
   docker stats
   ```
   Adjust memory limits in `docker-compose.yml` if needed.

6. **Regular backups**
   - Backup `./data/postgres` (Prefect state)
   - Backup `./outputs` (flow results)

---

## Additional Resources

- **Quick Start Guide**: [QUICK_START.md](QUICK_START.md)
- **Prefect Documentation**: https://docs.prefect.io/
- **Prefect Deployment Guide**: https://docs.prefect.io/latest/concepts/deployments/
- **Cron Expression Generator**: https://crontab.guru/
- **Docker Compose Reference**: https://docs.docker.com/compose/

---

## Summary

This tutorial covered:
- ✅ Setting up Prefect with Docker
- ✅ Creating flows with tasks
- ✅ Deploying flows with schedules
- ✅ Monitoring and troubleshooting
- ✅ Example: Daily backup at 3:00 AM

**Next steps:**
1. Create your own flows in `scripts/`
2. Add `.deploy()` at the end with your desired schedule
3. Run the script to deploy
4. Monitor executions in the UI

For quick reference, see [QUICK_START.md](QUICK_START.md).
